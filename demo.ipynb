{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# QandA Demo\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the `QandA` class from `qanda.py`, a RAG system for extracting information from coroner's reports. It uses local LLMs (Ollama) for secure processing, aligning with project aims: automating extraction of road fatality details (e.g., deceased info, causes, circumstances) from unstructured PDFs.\n",
    "\n",
    "Key demo steps: Initialize, query (basic/verbose), evaluate with BERTScore, and compare models.\n",
    "\n",
    "### Prerequisites\n",
    "- `conda activate coroner_env`\n",
    "- Ollama running with `mxbai-embed-large`, `gemma3`, `llama3.2`, and `phi4-mini` pulled.\n",
    "- `jsondata/Rodier-Finding.jsonl` available (pre-processed chunks from PDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "libs-cell",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "from qanda import QandA\n",
    "from scores import calculate_bertscore_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qanda-desc",
   "metadata": {},
   "source": [
    "## QandA Object\n",
    "\n",
    "`QandA` encapsulates the RAG pipeline: loads JSONL chunks, embeds into vector store, retrieves top-K contexts, generates LLM answers grounded in documents. Supports project deliverables (2.1.II: RAG integration for contextual queries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-desc",
   "metadata": {},
   "source": [
    "## Initialize QandA\n",
    "\n",
    "Parameters:\n",
    "- `file_path`: JSONL with chunks/metadata.\n",
    "- `gen_model`: LLM (e.g., `gemma3`).\n",
    "- `embed_model`: For semantic search.\n",
    "- `vdb`: In-memory store for demo speed.\n",
    "- `top_k`: Context chunks (3 balances relevance/token limits).\n",
    "- `prompt`: Grounds answers in context (mitigates hallucinations, per Section 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = Path(\"jsondata/Rodier-Finding.jsonl\")\n",
    "GEN_MODEL = \"gemma3\"\n",
    "EMBED_MODEL = \"mxbai-embed-large\"\n",
    "VDB = InMemoryVectorStore\n",
    "TOP_K = 3\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Context information is below.\n",
    "    \\n---------------------\\n\n",
    "    {context}\n",
    "    \\n---------------------\\n\n",
    "    Given the context information and not prior knowledge, answer the query.\\n\n",
    "    Query: {input}\\n\n",
    "    Answer:\\n\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "init-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing, please wait...\n",
      "Loading jsondata\\Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n"
     ]
    }
   ],
   "source": [
    "qanda = QandA(gen_model=GEN_MODEL,\n",
    "              embed_model=EMBED_MODEL, \n",
    "              vdb=VDB,\n",
    "              file_path=FILE_PATH,\n",
    "              top_k=TOP_K,\n",
    "              prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "help-desc",
   "metadata": {},
   "source": [
    "## Usage Help\n",
    "\n",
    "See docstring for `ask(question, verbose=False)`: Returns answer (or (answer, sources) if verbose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "help-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on QandA in module qanda object:\n",
      "\n",
      "class QandA(builtins.object)\n",
      " |  QandA(gen_model, embed_model, vdb, file_path, top_k, prompt)\n",
      " |\n",
      " |  A class for performing question-answering tasks using a language model and a vector database.\n",
      " |\n",
      " |  Attributes:\n",
      " |      gen_model (str): The name of the language model to be used for generating answers.\n",
      " |      embed_model (str): The name of the embedding model to be used for generating embeddings.\n",
      " |      vdb (str): The name of the vector database to be used for storing and retrieving documents.\n",
      " |      file_path (str): The path to the file containing the documents to be used for the question-answering task.\n",
      " |      top_k (int): The number of top-k most relevant documents to be retrieved for each question.\n",
      " |      prompt (str): The prompt to be used for the question-answering chain.\n",
      " |\n",
      " |  Methods:\n",
      " |      ask(question, verbose=False):\n",
      " |          Invokes the question-answering chain to generate an answer to the given question.\n",
      " |          Args:\n",
      " |              question (str): The question to be answered.\n",
      " |              verbose (bool, optional): If True, the method will return the answer and the sources used to generate the answer. Defaults to False.\n",
      " |          Returns:\n",
      " |              str or (str, list): The answer to the question, or a tuple containing the answer and the sources used to generate the answer.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, gen_model, embed_model, vdb, file_path, top_k, prompt)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  ask(self, question, verbose=False)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(qanda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-desc",
   "metadata": {},
   "source": [
    "## Querying Examples\n",
    "\n",
    "Target key info: coroner, deceased, cause (per 2.1: structured outputs for analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-desc",
   "metadata": {},
   "source": [
    "### Basic Queries\n",
    "\n",
    "`ask(question)`: Direct answers for quick extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "basic-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:  Sarah Helen Linton, Deputy State Coroner.\n",
      "Answer 2:  Frank Edward Rodier is the deceased.\n",
      "Answer 3:  The cause of death remains unascertained. The report states, “his cause of death must remain unascertained.” It suggests he likely died from injuries sustained from the rocks, but this is not definitively established.\n"
     ]
    }
   ],
   "source": [
    "QUESTIONS = [\"Who is the coroner?\", \"Who is the deceased?\", \"What was the cause of death?\"]\n",
    "LLM_ANSWERS = []\n",
    "\n",
    "for i, QUESTION in enumerate(QUESTIONS):\n",
    "    ANSWER = qanda.ask(QUESTION)\n",
    "    LLM_ANSWERS.append(ANSWER)\n",
    "    print(f\"Answer {i + 1}: \", ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbose-desc",
   "metadata": {},
   "source": [
    "### Verbose Queries\n",
    "\n",
    "`ask(question, verbose=True)`: Includes sources (text, page, doc) for auditing (2.1.II: source auditing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verbose-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Who is the coroner?\n",
      "Answer: Sarah Helen Linton, Deputy State Coroner.\n",
      "\n",
      "Sources:\n",
      "  Source 1:\n",
      "    Text: Counsel Appearing:\n",
      "Senior Constable C Robertson assisted the Coroner .\n",
      "Case(s) referred to in decision(s):\n",
      "Nil...\n",
      "    Page: 1, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "  Source 2:\n",
      "    Text: [2024] WACOR 35\n",
      "Coroners Act 1996 (Section 26(1))...\n",
      "    Page: 2, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "  Source 3:\n",
      "    Text: [2024] WACOR 35\n",
      "JURISDICTION\n",
      "CORONER'S COURT OF WESTERN AUSTRALIA\n",
      "ACT\n",
      "CORONERS ACT 1996\n",
      "CORONER\n",
      "SARAH HELEN LINTON, DEPUTY STATE CORONER\n",
      "HEARD\n",
      "14 AUGUST 2024\n",
      "DELIVERED\n",
      "14 AUGUST 2024\n",
      "FILE NO/S\n",
      "CORC 32...\n",
      "    Page: 1, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "--------------------------------------------------\n",
      "Question 2: Who is the deceased?\n",
      "Answer: Frank Edward Rodier\n",
      "\n",
      "Sources:\n",
      "  Source 1:\n",
      "    Text: IS DEATH ESTABLISHED?\n",
      "17. As is clear from the above; I am satisfied beyond reasonable doubt that Frank Rodier is deceased and that he died on 25 1975 in the sea after he was washed off the rocks whil...\n",
      "    Page: 6, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "  Source 2:\n",
      "    Text: INTRODUCTION\n",
      "- 2 In my capacity as the Acting State Coroner, I determined on the basis of information provided by the WA Police in August 2023 that   there was   reasonable cause to suspect that Frank...\n",
      "    Page: 3, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "  Source 3:\n",
      "    Text: RECORD OF INVESTIGATION INTO DEATH\n",
      "I, Sarah Helen Linton; Deputy State Coroner , having investigated the death of Frank Edward RODIER with an inquest  held at Perth Coroners Court; Central Law Courts,...\n",
      "    Page: 2, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "--------------------------------------------------\n",
      "Question 3: What was the cause of death?\n",
      "Answer: The cause of death remains unascertained. The report states: “Accordingly, his cause of death must remain unascertained.”\n",
      "\n",
      "Sources:\n",
      "  Source 1:\n",
      "    Text: IS DEATH ESTABLISHED?\n",
      "17. As is clear from the above; I am satisfied beyond reasonable doubt that Frank Rodier is deceased and that he died on 25 1975 in the sea after he was washed off the rocks whil...\n",
      "    Page: 6, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "  Source 2:\n",
      "    Text: INTRODUCTION\n",
      "- 2 In my capacity as the Acting State Coroner, I determined on the basis of information provided by the WA Police in August 2023 that   there was   reasonable cause to suspect that Frank...\n",
      "    Page: 3, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "  Source 3:\n",
      "    Text: [2024] WACOR 35\n",
      "impediment; associated with events at the time of his birth. He had no known medical conditions that would have shortened his life span: 3...\n",
      "    Page: 4, Document: data/Rodier-Finding.pdf\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, QUESTION in enumerate(QUESTIONS):\n",
    "    ANSWER, SOURCES = qanda.ask(QUESTION, verbose=True)\n",
    "    print(f\"Question {i + 1}: {QUESTION}\")\n",
    "    print(f\"Answer: {ANSWER}\\n\")\n",
    "    print(\"Sources:\")\n",
    "    for src in SOURCES:\n",
    "        print(f\"  Source {src['source']}:\")\n",
    "        print(f\"    Text: {src['text'][:200]}...\")\n",
    "        print(f\"    Page: {src['page']}, Document: {src['document']}\\n\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-desc",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "BERTScore on basic answers vs. ground-truth (from PDF manual review). Measures semantic accuracy for consistency (Benefits III)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eval-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb4a1699400421ba8a08499194b7fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9662a25aa24988b904f84c12a0f3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.85 seconds, 1.62 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>QUESTION</th>\n",
       "      <th>CORRECT_ANSWER</th>\n",
       "      <th>LLM_ANSWER</th>\n",
       "      <th>BERT_PRECISION</th>\n",
       "      <th>BERT_RECALL</th>\n",
       "      <th>BERT_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rodier-Finding</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>Who is the coroner?</td>\n",
       "      <td>Sarah Helen Linton</td>\n",
       "      <td>Sarah Helen Linton, Deputy State Coroner.</td>\n",
       "      <td>0.888055</td>\n",
       "      <td>0.959326</td>\n",
       "      <td>0.922316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rodier-Finding</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>Who is the deceased?</td>\n",
       "      <td>Frank Edward Rodier</td>\n",
       "      <td>Frank Edward Rodier is the deceased.</td>\n",
       "      <td>0.913599</td>\n",
       "      <td>0.961740</td>\n",
       "      <td>0.937052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rodier-Finding</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>What was the cause of death?</td>\n",
       "      <td>unascertained</td>\n",
       "      <td>The cause of death remains unascertained. The ...</td>\n",
       "      <td>0.814397</td>\n",
       "      <td>0.838729</td>\n",
       "      <td>0.826384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FILENAME   MODEL                      QUESTION       CORRECT_ANSWER  \\\n",
       "0  Rodier-Finding  gemma3           Who is the coroner?   Sarah Helen Linton   \n",
       "1  Rodier-Finding  gemma3          Who is the deceased?  Frank Edward Rodier   \n",
       "2  Rodier-Finding  gemma3  What was the cause of death?        unascertained   \n",
       "\n",
       "                                          LLM_ANSWER  BERT_PRECISION  \\\n",
       "0          Sarah Helen Linton, Deputy State Coroner.        0.888055   \n",
       "1               Frank Edward Rodier is the deceased.        0.913599   \n",
       "2  The cause of death remains unascertained. The ...        0.814397   \n",
       "\n",
       "   BERT_RECALL   BERT_F1  \n",
       "0     0.959326  0.922316  \n",
       "1     0.961740  0.937052  \n",
       "2     0.838729  0.826384  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.895\n"
     ]
    }
   ],
   "source": [
    "CORRECT_ANSWERS = [\"Sarah Helen Linton\", \"Frank Edward Rodier\", \"unascertained\"]\n",
    "\n",
    "data = {\n",
    "    'FILENAME': ['Rodier-Finding'] * len(QUESTIONS),\n",
    "    'MODEL': [GEN_MODEL] * len(QUESTIONS),\n",
    "    'QUESTION': QUESTIONS,\n",
    "    'CORRECT_ANSWER': CORRECT_ANSWERS,\n",
    "    'LLM_ANSWER': LLM_ANSWERS\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "scores_df = calculate_bertscore_df(df)\n",
    "\n",
    "display(scores_df)\n",
    "print(f\"Average F1 Score: {scores_df['BERT_F1'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi-model-desc",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------ \n",
    "# Method 4: Compare answers of different models\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "This section initializes QandA instances for multiple LLMs and compares their responses to a targeted question on the report. It evaluates semantic similarity via BERTScore, highlighting model strengths for project scalability (Benefit II: Associative studies across models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "multi-model-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing, please wait...\n",
      "Loading jsondata\\Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n",
      "Initializing, please wait...\n",
      "Loading jsondata\\Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n",
      "Initializing, please wait...\n",
      "Loading jsondata\\Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n",
      "Answer 1:  Based on the provided context information, the activity implicated in the cause of death is fishing. Frank Rodier was washed off the rocks while fishing with friends, which led to his death in 1975.\n",
      "Answer 2:  Fishing with friends.\n",
      "Answer 3:  The activity implied to be related to Frank Rodier's cause of death is fishing with friends. He died after being washed off rocks while engaging in this activity on 25 July 1975. The manner suggested by the context for his demise appears accidental, as he was likely overwhelmed or unable to swim back safely due to a sudden wave at sea during an outing that included swimming and diving activities among other pursuits related to fishing with friends.\n",
      "\n",
      "In summary:\n",
      "\n",
      "- Activity implicated in cause of death: Fishing (specifically involving being washed off rocks while accompanied by others for this activity).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcb48b7e980402680cc8eb9308fc52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2cb84e732e4aca9ee877d920a612e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.22 seconds, 1.35 sentences/sec\n",
      "Index(['FILENAME', 'MODEL', 'QUESTION', 'CORRECT_ANSWER', 'LLM_ANSWER',\n",
      "       'BERT_PRECISION', 'BERT_RECALL', 'BERT_F1'],\n",
      "      dtype='object')\n",
      "         FILENAME      MODEL  \\\n",
      "0  Rodier-Finding   llama3.2   \n",
      "1  Rodier-Finding     gemma3   \n",
      "2  Rodier-Finding  phi4-mini   \n",
      "\n",
      "                                            QUESTION CORRECT_ANSWER  \\\n",
      "0  What activity was implicated in the cause of d...        Fishing   \n",
      "1  What activity was implicated in the cause of d...        Fishing   \n",
      "2  What activity was implicated in the cause of d...        Fishing   \n",
      "\n",
      "                                          LLM_ANSWER  BERT_PRECISION  \\\n",
      "0  Based on the provided context information, the...        0.805051   \n",
      "1                              Fishing with friends.        0.866990   \n",
      "2  The activity implied to be related to Frank Ro...        0.768712   \n",
      "\n",
      "   BERT_RECALL   BERT_F1  \n",
      "0     0.821265  0.813078  \n",
      "1     0.888260  0.877496  \n",
      "2     0.866824  0.814825  \n"
     ]
    }
   ],
   "source": [
    "LLAMA = \"llama3.2\"\n",
    "GEMMA = \"gemma3\"\n",
    "PHI   = \"phi4-mini\"\n",
    "\n",
    "qanda_llama = QandA(gen_model=LLAMA,\n",
    "                    embed_model=EMBED_MODEL, \n",
    "                    vdb=VDB,\n",
    "                    file_path=FILE_PATH,\n",
    "                    top_k=TOP_K,\n",
    "                    prompt=PROMPT)\n",
    "\n",
    "qanda_gemma = QandA(gen_model=GEMMA,\n",
    "                    embed_model=EMBED_MODEL, \n",
    "                    vdb=VDB,\n",
    "                    file_path=FILE_PATH,\n",
    "                    top_k=TOP_K,\n",
    "                    prompt=PROMPT)\n",
    "\n",
    "qanda_phi = QandA(gen_model=PHI,\n",
    "                  embed_model=EMBED_MODEL, \n",
    "                  vdb=VDB,\n",
    "                  file_path=FILE_PATH,\n",
    "                  top_k=TOP_K,\n",
    "                  prompt=PROMPT)\n",
    "\n",
    "QUESTION = \"What activity was implicated in the cause of death?\"\n",
    "CORRECT_ANSWER = \"Fishing\"\n",
    "LLM_ANSWERS = []\n",
    "\n",
    "for i, qanda_model in enumerate([qanda_llama, qanda_gemma, qanda_phi]):\n",
    "    ANSWER = qanda_model.ask(QUESTION)\n",
    "    LLM_ANSWERS.append(ANSWER)\n",
    "    print(f\"Answer {i + 1}: \", ANSWER)\n",
    "\n",
    "data = {\n",
    "    'FILENAME': ['Rodier-Finding'] * 3,\n",
    "    'MODEL': [LLAMA, GEMMA, PHI],\n",
    "    'QUESTION': [QUESTION] * 3,\n",
    "    'CORRECT_ANSWER': [CORRECT_ANSWER] * 3,\n",
    "    'LLM_ANSWER': LLM_ANSWERS\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "scores_df = calculate_bertscore_df(df)\n",
    "\n",
    "print(scores_df.columns)\n",
    "\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps for WACRSR\n",
    "\n",
    "- Bulk process: Loop over JSONL files for associative studies (Benefit II).\n",
    "- Visualize: Aggregate outputs (e.g., Pandas for trends; Week 7-8).\n",
    "- New reports: OCR preprocess (Week 3-5).\n",
    "\n",
    "Enables tackling road fatalities scalably (Aim)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
