{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786dccb0-89e8-4891-9459-da3e9ed64f21",
   "metadata": {},
   "source": [
    "# QandA Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be58f4-4ee4-4b3c-bc52-49559c4e006f",
   "metadata": {},
   "source": [
    "## Libraries etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eaa5cc6-de5d-40ec-810a-089a48fe394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "from qanda import QandA\n",
    "from scores import calculate_bertscore_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2351b8-cbd2-4e78-9ec0-26a4d9b6aa62",
   "metadata": {},
   "source": [
    "## The QandA Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37405c52-2df5-4240-b513-b49968307ca1",
   "metadata": {},
   "source": [
    "A `QandA` object is a RAG (Retrieval-Augmented Generation) question-answer chain encapsulated in a simple Python object. It exposes a single primary method, `ask()`, for ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6fd3a-3b73-48a1-bb08-d64da47b0181",
   "metadata": {},
   "source": [
    "## Initialize a QandA Object\n",
    "To create an instance of the `QandA` class, you need to provide the following parameters:\n",
    "- `file_path`: The path to your document (`.jsonl` format).\n",
    "- `gen_model`: The generative LLM you wish to use (e.g., \"gemma3\", \"llama3.2\").\n",
    "- `embed_model`: The embedding model for the vector store.\n",
    "- `vdb`: The vector store class to use (e.g., `InMemoryVectorStore`).\n",
    "- `top_k`: The number of relevant document chunks to retrieve for context.\n",
    "- `prompt`: The prompt template for the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108810e7-d90d-4bad-979e-07ae3ebaf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = Path(\"jsondata/Rodier-Finding.jsonl\")\n",
    "GEN_MODEL = \"gemma3\"\n",
    "EMBED_MODEL = \"mxbai-embed-large\"\n",
    "VDB = InMemoryVectorStore\n",
    "TOP_K = 3\n",
    "\n",
    "PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Context information is below.\\n\n",
    "    ---------------------\\n\n",
    "    {context}\\n\n",
    "    ---------------------\\n\n",
    "    Given the context information and not prior knowledge, answer the query.\\n\n",
    "    Query: {input}\\n\n",
    "    Answer:\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43161b41-d629-4890-a81f-49c8d7e57c3e",
   "metadata": {},
   "source": [
    "Now we can instantiate the `QandA` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6820c549-b7ec-4e42-8218-130afa7183ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing, please wait...\n",
      "Loading jsondata\\Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n"
     ]
    }
   ],
   "source": [
    "qanda = QandA(gen_model=GEN_MODEL,\n",
    "              embed_model=EMBED_MODEL, \n",
    "              vdb=VDB,\n",
    "              file_path=FILE_PATH,\n",
    "              top_k=TOP_K,\n",
    "              prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b211a3-211c-4abf-a32a-38b87a466458",
   "metadata": {},
   "source": [
    "The object is now ready. We can inspect its documentation using the `help()` function to understand its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3319e5b-dd8b-46a9-8d78-a82da01edb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on QandA in module qanda object:\n",
      "\n",
      "class QandA(builtins.object)\n",
      " |  QandA(gen_model, embed_model, vdb, file_path, top_k, prompt)\n",
      " |\n",
      " |  A class for performing question-answering tasks using a language model and a vector database.\n",
      " |\n",
      " |  Attributes:\n",
      " |      gen_model (str): The name of the language model to be used for generating answers.\n",
      " |      embed_model (str): The name of the embedding model to be used for generating embeddings.\n",
      " |      vdb (str): The name of the vector database to be used for storing and retrieving documents.\n",
      " |      file_path (str): The path to the file containing the documents to be used for the question-answering task.\n",
      " |      top_k (int): The number of top-k most relevant documents to be retrieved for each question.\n",
      " |      prompt (str): The prompt to be used for the question-answering chain.\n",
      " |\n",
      " |  Methods:\n",
      " |      ask(question, verbose=False):\n",
      " |          Invokes the question-answering chain to generate an answer to the given question.\n",
      " |          Args:\n",
      " |              question (str): The question to be answered.\n",
      " |              verbose (bool, optional): If True, the method will return the answer and the sources used to generate the answer. Defaults to False.\n",
      " |          Returns:\n",
      " |              str or (str, list): The answer to the question, or a tuple containing the answer and the sources used to generate the answer.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, gen_model, embed_model, vdb, file_path, top_k, prompt)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  ask(self, question, verbose=False)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(qanda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582469d6-2b74-4096-87cb-2eaa6b851673",
   "metadata": {},
   "source": [
    "## How to Use the QandA Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c00a6-c956-427c-9e6e-c6c74d0d087c",
   "metadata": {},
   "source": [
    "### 1. Basic Usage: Getting an Answer\n",
    "\n",
    "The simplest way to use the object is to call the `ask()` method with a question. This will return the generated answer as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d584ba7d-bd64-44bd-84c3-684e4964e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the coroner?\n",
      "Answer: Sarah Helen Linton, Deputy State Coroner.\n",
      "\n",
      "Question: Who is the deceased?\n",
      "Answer: Frank Edward Rodier is the deceased.\n",
      "\n",
      "Question: What was the cause of death?\n",
      "Answer: The cause of death remains unascertained. The report states: “Accordingly, his cause of death must remain unascertained.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QUESTIONS = [\n",
    "    \"Who is the coroner?\", \n",
    "    \"Who is the deceased?\", \n",
    "    \"What was the cause of death?\"\n",
    "]\n",
    "\n",
    "for question in QUESTIONS:\n",
    "    answer = qanda.ask(question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7e68b-59b3-4f93-85e6-c731e5f8f30e",
   "metadata": {},
   "source": [
    "### 2. Verbose Usage: Getting the Answer and Sources\n",
    "\n",
    "To verify the answer and see which parts of the document were used as context, you can set `verbose=True`. This returns a tuple containing the answer and a list of source documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90346aed-3080-4e05-a3b9-e5854e6bb146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the coroner?\n",
      "Answer: Sarah Helen Linton, Deputy State Coroner.\n",
      "Sources:\n",
      "  Source 1:\n",
      "    - Text: Counsel Appearing: Senior Constable C Robertson assisted the Coroner . Case(s) referred to in decision(s): Nil...\n",
      "    - Page: 1\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "  Source 2:\n",
      "    - Text: [2024] WACOR 35 Coroners Act 1996 (Section 26(1))...\n",
      "    - Page: 2\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "  Source 3:\n",
      "    - Text: [2024] WACOR 35 JURISDICTION CORONER'S COURT OF WESTERN AUSTRALIA ACT CORONERS ACT 1996 CORONER SARAH HELEN LINTON, DEPUTY STATE CORONER HEARD 14 AUGUST 2024 DELIVERED 14 AUGUST 2024 FILE NO/S CORC 32...\n",
      "    - Page: 1\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: Who is the deceased?\n",
      "Answer: Frank Edward Rodier is the deceased.\n",
      "Sources:\n",
      "  Source 1:\n",
      "    - Text: IS DEATH ESTABLISHED? 17. As is clear from the above; I am satisfied beyond reasonable doubt that Frank Rodier is deceased and that he died on 25 1975 in the sea after he was washed off the rocks whil...\n",
      "    - Page: 6\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "  Source 2:\n",
      "    - Text: INTRODUCTION - 2 In my capacity as the Acting State Coroner, I determined on the basis of information provided by the WA Police in August 2023 that   there was   reasonable cause to suspect that Frank...\n",
      "    - Page: 3\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "  Source 3:\n",
      "    - Text: RECORD OF INVESTIGATION INTO DEATH I, Sarah Helen Linton; Deputy State Coroner , having investigated the death of Frank Edward RODIER with an inquest  held at Perth Coroners Court; Central Law Courts,...\n",
      "    - Page: 2\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "\n",
      "--------------------------------------------------\n",
      "Question: What was the cause of death?\n",
      "Answer: The cause of death remains unascertained. The coroner determined that while Frank Rodier likely died by accident (washed off the rocks while fishing), the injuries sustained from the rocks may have contributed to his death, and the exact cause couldn’t be established.\n",
      "Sources:\n",
      "  Source 1:\n",
      "    - Text: IS DEATH ESTABLISHED? 17. As is clear from the above; I am satisfied beyond reasonable doubt that Frank Rodier is deceased and that he died on 25 1975 in the sea after he was washed off the rocks whil...\n",
      "    - Page: 6\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "  Source 2:\n",
      "    - Text: INTRODUCTION - 2 In my capacity as the Acting State Coroner, I determined on the basis of information provided by the WA Police in August 2023 that   there was   reasonable cause to suspect that Frank...\n",
      "    - Page: 3\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "  Source 3:\n",
      "    - Text: [2024] WACOR 35 impediment; associated with events at the time of his birth. He had no known medical conditions that would have shortened his life span: 3...\n",
      "    - Page: 4\n",
      "    - Document: data/Rodier-Finding.pdf\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for question in QUESTIONS:\n",
    "    answer, sources = qanda.ask(question, verbose=True)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"Sources:\")\n",
    "    for src in sources:\n",
    "        \n",
    "        text_preview = src['text'].replace('\\n', ' ')[:200] + '...'\n",
    "        print(f\"  Source {src['source']}:\")\n",
    "        print(f\"    - Text: {text_preview}\")\n",
    "        print(f\"    - Page: {src['page']}\")\n",
    "        print(f\"    - Document: {src['document']}\")\n",
    "    print(\"\\n\" + \"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d3d75-6e4e-4f7f-8d9e-1d575c970404",
   "metadata": {},
   "source": [
    "### 3. Programmatic Evaluation\n",
    "\n",
    "For more systematic testing, we can compare the model's answers against a set of known correct answers. Here, we use the `bert_score` library to numerically evaluate the semantic similarity between the generated answer and the ground truth.\n",
    "\n",
    "The process involves:\n",
    "1. Defining a list of questions and their corresponding correct answers.\n",
    "2. Generating answers from the LLM for each question.\n",
    "3. Creating a pandas DataFrame to hold the questions, correct answers, and LLM answers.\n",
    "4. Using the `calculate_bertscore_df` function from the `scores` module to compute precision, recall, and F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01de5e5-9fd1-4ba8-807b-5362bee6a246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LLM answers for evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b788c7324d4486aaba1105437854c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a5df12f2514408b8c4ffc7c0447dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.67 seconds, 1.79 sentences/sec\n",
      "Evaluation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>QUESTION</th>\n",
       "      <th>CORRECT_ANSWER</th>\n",
       "      <th>LLM_ANSWER</th>\n",
       "      <th>BERT_PRECISION</th>\n",
       "      <th>BERT_RECALL</th>\n",
       "      <th>BERT_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rodier-Finding</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>Who is the coroner?</td>\n",
       "      <td>Sarah Helen Linton</td>\n",
       "      <td>Sarah Helen Linton, Deputy State Coroner.</td>\n",
       "      <td>0.888055</td>\n",
       "      <td>0.959326</td>\n",
       "      <td>0.922316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rodier-Finding</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>Who is the deceased?</td>\n",
       "      <td>Frank Edward Rodier</td>\n",
       "      <td>Frank Edward Rodier is the deceased.</td>\n",
       "      <td>0.913599</td>\n",
       "      <td>0.961740</td>\n",
       "      <td>0.937052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rodier-Finding</td>\n",
       "      <td>gemma3</td>\n",
       "      <td>What was the cause of death?</td>\n",
       "      <td>unascertained</td>\n",
       "      <td>The cause of death remains unascertained. The ...</td>\n",
       "      <td>0.808263</td>\n",
       "      <td>0.863161</td>\n",
       "      <td>0.834811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FILENAME   MODEL                      QUESTION       CORRECT_ANSWER  \\\n",
       "0  Rodier-Finding  gemma3           Who is the coroner?   Sarah Helen Linton   \n",
       "1  Rodier-Finding  gemma3          Who is the deceased?  Frank Edward Rodier   \n",
       "2  Rodier-Finding  gemma3  What was the cause of death?        unascertained   \n",
       "\n",
       "                                          LLM_ANSWER  BERT_PRECISION  \\\n",
       "0          Sarah Helen Linton, Deputy State Coroner.        0.888055   \n",
       "1               Frank Edward Rodier is the deceased.        0.913599   \n",
       "2  The cause of death remains unascertained. The ...        0.808263   \n",
       "\n",
       "   BERT_RECALL   BERT_F1  \n",
       "0     0.959326  0.922316  \n",
       "1     0.961740  0.937052  \n",
       "2     0.863161  0.834811  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Defining questions and ground truth answers\n",
    "CORRECT_ANSWERS = [\n",
    "    \"Sarah Helen Linton\",\n",
    "    \"Frank Edward Rodier\",\n",
    "    \"unascertained\"\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Generating LLM answers for evaluation...\")\n",
    "llm_answers = [qanda.ask(q) for q in QUESTIONS]\n",
    "\n",
    "data = {\n",
    "    'FILENAME': [FILE_PATH.stem] * len(QUESTIONS),\n",
    "    'MODEL': [GEN_MODEL] * len(QUESTIONS),\n",
    "    'QUESTION': QUESTIONS,\n",
    "    'CORRECT_ANSWER': CORRECT_ANSWERS,\n",
    "    'LLM_ANSWER': llm_answers\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "scores_df = calculate_bertscore_df(df)\n",
    "\n",
    "# results\n",
    "print(\"Evaluation Results:\")\n",
    "display(scores_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8f2f4-1a75-46e9-8638-4279df3c2302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
